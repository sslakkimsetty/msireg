---
title: "Quantitative metrics for evaluating registration performance"
author: "Sai Srikanth Lakkimsetty"
date: "July, 2022"
output:
    BiocStyle::html_document:
    toc: true 
vignette: >
  %\VignetteIndexEntry{Quantitative metrics for evaluating registration performance}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r flags, echo=FALSE}
# A flag to manage chunk re-runs while knitting 
# (could also use cache option, but tricky) 
# Set SHARING to FALSE if you are re-knitting the code and variables are already 
# in the environment. Manage individual code chunk evaluation with "eval" option. 
SHARING <- FALSE 

# Save default parameters of graphics for resetting at the end of the session. 
def.par <- par(no.readonly=TRUE)
```


```{r style, echo=FALSE, results='asis', eval=TRUE}
BiocStyle::markdown()
```


```{r setup, echo=FALSE, message=FALSE}
library("Cardinal")
library("Rtsne")
library("SimpleITK")
library("EBImage")
library("ggplot2")
```


```{r metrics, echo=FALSE, eval=SHARING} 
def.par <- par(no.readonly=TRUE)
coregPlotOverlays <- function(plots, global_title=NA, aspect_ratio=(8/5), 
                              height=10, quartz=FALSE, plot_config=c(1,2,3,4), 
                              ncol=2) { 
    titles <- c("Prior registration", "Post registration")
    nrow <- length(plot_config) / ncol 
    width <- aspect_ratio * height * (ncol / nrow)
    
    # Set output device and configure 
    if (quartz) { 
        quartz(title=global_title, width=width, height=height) 
    } 
    # else {
    #     dev.new(title=global_title, width=width, height=height) 
    # }
    
    par(mar=c(2, 2, 2, 2))
    pl <- layout(mat=matrix(plot_config, ncol=ncol, byrow=TRUE), 
                 heights=rep(height/nrow, nrow), 
                 widths=rep(width/ncol, ncol), 
                 respect=TRUE)
    sapply(seq_along(plots), function(x) {
        plot.new()
        rasterImage(standardScaler(as.array(transpose(plots[[x]]))), xleft=0, 
                    xright=1, ytop=0, ybottom=1, interpolate=FALSE)
        title(titles[x])
    }) 
    par(def.par)
} 
```



# Introduction

This notebook focuses on quantitative metrics adopted in the literature for 
assessing registration performance. The state of the art in clinical registration 
is either 
* use landmark based registration, or [!TODO - list software, Melanie]
* use automated affine transformation based registration (e.g., Galaxy)

It is notable that while automated and unsupervised registration techniques 
exist in the wild (e.g., SimpleITK, voxelmorph ...), these are not yet fully 
adopted for clinical applications outside of the labs that've developed these 
methods [!TODO - get confirmation from Melanie]. 

A primary reason (SPECULATING!!! [!TODO - needs Melanie's insights]) could be 
attributed to the evaluation of the registration performance. (Another is the 
technical expertise needed to understand the methods / software is higher!)

Automated and unsupervised registration, by definition, does not need user's 
input for landmarks / annotations in the images. This also affects the way 
we evaluate the quality of the registration. If landmarks were present, we could 
develop a method around the relative distances between landmarks ante- and post-registration. 
If regions were annotated, we could apply  Hausdorff distance to gather insights 
as to how well the method performed. 

However, these are not possible with **automated and unsupervised** registration. 
Furthermore, these questions remain, 

* Did the registration perform satisfactorily globally? 
* Were local deformations resolved? 
* Did the registration induce any folds in the "canvas"? 

There is no **single** metric that answers all of the above questions. However, 
a set of metrics could be developed and tuned to answer specific questions. Some 
of them are below. 

* Sørensen-Dice coef. - Dice 
* Jaccard's similarity index 
* Normalized gradient field - Modersitzki & Haber 
* Mutual information - Viola & Wells 
* Normalized MI - Studholme et. al. 
* Correlation ratio - Roche et. al. 
* Woods function - Woods et. al. 
* Dense vector field jacobian 

The essential idea is to start with various image similarity measuring metrics 
and adapt them to apply for image registration evaluation. Dice coefficient, 
Jaccard's index, mutual information, normalized MI, and the correlation 
ratio provide insight into the global registration. Normalized gradient field 
deals with the local registration quality. Dense vector field jacobian computes 
and visualizes the artefacts induced by the registration process. 



# Sørensen-Dice Similarity Coefficient^[[1](https://support.brainvoyager.com/images/documents/Available_Tools/Available_Scripts/python/ImageRegistrationEvaluationViaDiceCoefficientInBV_v02.pdf)]^ 

The Dice coefficient, `D` is essentially the percentage of area that is overlapping 
between the optical and MS image. 

$A$, $B$ are the images represented on the coordinate grid. $\cap$ represents 
the overlapped area between two images. 

$$ 
D = \frac{2 \mid A \cap B \mid}{\mid A \mid + \mid B \mid} 
$$

Pros: 

* `D` is very simple to compute and report 

Cons: 

* `D` is so simple that it only speaks to global (mis-) alignment. 
* Very **wrong** registrations can actually have close-to-100% Dice coefficient. 
For example consider the setting of affine transformation where the rotation is 
90$^\circ$. The overall overlap would still be significantly high but the 
registration task has failed. So, reporting just (or optimizing for) `D` is 
not a good idea. 


## Implementation details 

Overlaps are computed using binary masks generated from, 
    * Fiji (ImageJ) for optical images. 
    * Cardinal for MS images. 

MS image's binary mask is just resampled with transformation to generate 
transformed moving image's mask. 


```{r dice, eval=SHARING} 
diceCoef <- function(mask1, mask2) {
    # Check for all masks to be of identical size. 
    # [!TODO] check 
    
    composite <- ((mask1 + mask2) / 2) - 0.005 
    composite <- ifelse(composite > 0.5, 1, 0) 
    aINTb <- mean(composite) 
    a <- mean(mask1) 
    b <- mean(mask2) 
    (2 * aINTb) / (a + b)
}
```


```{r dice-test, warning=FALSE, eval=SHARING, echo=FALSE} 
DATAPATH <- "/Users/sai/Documents/00-NEU/2-Ind-Study/9-data"
CURRPATH <- "2-hr2msi-mouse-urinary-bladder" 
mask_name <- "2-mouse-bladder-mask.tif" 
opt_mask <- generateMaskFromFile(file.path(DATAPATH, CURRPATH, "images", mask_name))
mse_mask <- rasterizeROIFromCardinal(mse_peaks, tissue) 
mse_mask_u <- resizeMask(ref=opt_mask, target=mse_mask) 

mse_mask_itk <- SimpleITK::as.image(mse_mask, isVector=FALSE)
.mse_mask_itk_tx <- Resample(mse_mask_itk, outTx2) 
.mse_mask_itk_tx_arr <- as.array(.mse_mask_itk_tx)
.mse_mask_itk_tx_arr <- resizeMask(.mse_mask_itk_tx_arr, opt_mask) 

.nX <- dim(opt_mask)[1] 
.nY <- dim(opt_mask)[2]
```


## Results 

```{r dice-results, eval=TRUE} 
D_prior <- diceCoef(mse_mask_u, opt_mask) 
D_post <- diceCoef(opt_mask, .mse_mask_itk_tx_arr) 

overlay_prior <- as.Image(opt_mask) * 0.5 + as.Image(mse_mask_u) * 0.5 
overlay_post <- as.Image(opt_mask) * 0.5 + as.Image(.mse_mask_itk_tx_arr) * 0.5 

plots <- list(overlay_prior, overlay_post) 
coregPlotOverlays(plots, 
                  global_title="Mask overlays before and after registration", 
                  quartz=FALSE, aspect_ratio=(.nX/.nY), plot_config=c(1,2)) 

# Console only code 
# coregPlotOverlays(plots, 
#                   global_title="Mask overlays before and after registration", 
#                   quartz=TRUE, aspect_ratio=(.nX/.nY), plot_config=c(1,2))
```

Dice coefficient before registration is `r round(D_prior, 3)`.  
Dice coefficient after registration is `r round(D_post, 3)`.



# Normalized Mutual Information (NMI) 

Normalized mutual information is a modified version of MI. It solves the MI's 
problem of unboundedness. 

Below, $H$ is Shannon's entropy of an image and $A$, $B$ are the image intensities 
represented on the coordinate grid.

$$ 
MI = H(A) + H(B) - H(A,B)
$$
$$
NMI = \frac{H(A) + H(B)}{H(A,B)}
$$
$$ 
NMI = \frac{MI}{H(A,B)} + 1
$$


<!-- ## Implementation details 

* Use exisiting implementation from R scripts (MS thesis) 
* Use histograms (binning method) to estimate $H$. 


## Results  -->



# Normalized Cross Correlation (NCC) 

Just your garden variety correlation. $A$, $B$ are the image intensities 
represented on the coordinate grid, and $i$, $j$ are indices pointing to the 
pixels of the image. 

$$ 
NCC = \frac{\sum_{i=1}^{M}\sum_{j=1}^{N} (A(i,j) - \bar{A})(B(i,j) - \bar{B})}{\sqrt{\sum_{i=1}^{M}\sum_{j=1}^{N}(A(i,j) - \bar{A})^2 \sum_{i=1}^{M}\sum_{j=1}^{N}(B(i,j) - \bar{B})^2}}
$$


<!-- ## Implementation details 


## Results  -->



# Displacement field jacobian determinant 

The Jacobian, $J$'s determinant is used to measure the folding of a 
transformation. ***Folding*** is an artefact of the registration process wherein 
a location of the moving image is displaced beyond its neighbor _in that 
direction_. In other words, the image is made to fold onto itself. Folding 
is more common during more aggressive registration methods where smoothing or 
regularization is avoided. 

The Jacobian is expressed as a matrix of partial derivatives of components 
(displacements) with respect to the spatial coordinate system. 

$$ 
det(J(A,B)) = 
\begin{vmatrix} 
\frac{\partial{i}}{\partial{x}} & \frac{\partial{j}}{\partial{x}} \\ 
\frac{\partial{i}}{\partial{y}} & \frac{\partial{j}}{\partial{y}}
\end{vmatrix}
$$






















